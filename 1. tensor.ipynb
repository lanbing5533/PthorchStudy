{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor(1.)\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[[-0.8189,  0.1821, -0.7314, -1.3146, -0.1625],\n",
      "         [ 0.5218, -1.6122, -0.6681,  0.6638, -0.6357],\n",
      "         [-1.5875,  0.5964,  0.8344,  1.5509,  1.8045],\n",
      "         [ 1.0405, -0.2923,  0.7960, -0.7837,  0.4633]],\n",
      "\n",
      "        [[-0.4234, -1.1919,  1.2405, -0.2928,  0.6935],\n",
      "         [ 0.0583, -1.4217, -0.2596, -1.3041, -0.9261],\n",
      "         [-0.3782,  1.1511,  1.5498, -0.9098,  1.3734],\n",
      "         [-0.6867,  0.5426, -1.2608, -0.6211, -1.0209]],\n",
      "\n",
      "        [[-0.0547,  2.7389,  0.1277,  0.3586, -0.6732],\n",
      "         [-0.4873, -0.1533, -1.1152,  0.8455, -0.2956],\n",
      "         [-1.2063, -0.5460,  0.8690, -0.5858, -0.0741],\n",
      "         [ 0.3046, -0.7608,  0.3865,  0.7211,  0.5598]]])\n",
      "tensor([5., 7., 9.])\n",
      "tensor([[-4.4115e-01,  4.2064e-01,  5.3940e-01, -2.9033e-04,  5.8747e-01],\n",
      "        [ 1.1477e+00,  6.5739e-02, -9.6239e-01, -1.3706e+00, -1.2911e-01],\n",
      "        [ 9.1896e-01, -5.6797e-01, -3.0004e+00, -2.0013e+00, -7.4607e-01],\n",
      "        [-1.5955e+00, -1.3925e+00,  3.8967e-02, -8.2460e-01,  3.2338e-01],\n",
      "        [ 1.5579e-01,  1.6947e-01,  2.3851e+00,  4.1488e-01, -8.2711e-01]])\n",
      "tensor([[ 1.8278, -1.5253, -0.6090,  1.8119,  0.4274,  0.8631,  1.2904,  0.2475],\n",
      "        [-1.1472,  2.5228,  1.2559,  0.7034, -1.0143,  0.2966,  1.4312, -0.4403]])\n"
     ]
    }
   ],
   "source": [
    "# https://nbviewer.jupyter.org/   git 上不显示时， 复制文件链接到 nbviewer\n",
    "\n",
    "\n",
    "import torch\n",
    "# list to tensor\n",
    "v_data = [1., 2., 3.]\n",
    "v = torch.Tensor(v_data)\n",
    "print(v)\n",
    "print(v[0])\n",
    "m_data = [[1., 2., 3.],[4., 5., 6.]]\n",
    "m = torch.Tensor(m_data)\n",
    "print(m)\n",
    "print(m[0])\n",
    "t_data = [[[1.,2.],[3., 4.]],\n",
    "          [[5.,6.],[7., 8.]]]\n",
    "t = torch.Tensor(t_data)\n",
    "print(t)\n",
    "print(t[0])\n",
    "\n",
    "x = torch.randn((3, 4, 5))# 随机数\n",
    "print(x)\n",
    "\n",
    "# 张量间的数学运算\n",
    "x = torch.Tensor([1.,2.,3.])\n",
    "y = torch.Tensor([4.,5.,6.])\n",
    "z = x + y\n",
    "print(z)\n",
    "\n",
    "# Tensor 的拼接, 默认基于第一个维度进行拼接\n",
    "x1 = torch.randn(2, 5)\n",
    "y1 = torch.randn(3, 5)\n",
    "z1 = torch.cat([x1, y1])\n",
    "print(z1)\n",
    "\n",
    "x2 = torch.randn(2, 3)\n",
    "y2 = torch.randn(2, 5)\n",
    "z2 = torch.cat([x2, y2], 1) # 拼接的维度为1， 默认为0\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.0133,  0.1762,  0.0236, -0.7760],\n",
      "         [ 0.3458, -1.0979,  0.3646, -1.3126],\n",
      "         [-0.5476, -0.5698,  0.4259,  1.1555]],\n",
      "\n",
      "        [[ 2.0760, -1.0971,  0.6704, -0.8363],\n",
      "         [ 0.0697, -0.9179,  0.5418,  0.0224],\n",
      "         [-0.2133, -1.1332,  0.2417, -1.5240]]])\n",
      "tensor([[-2.0133,  0.1762,  0.0236, -0.7760,  0.3458, -1.0979,  0.3646, -1.3126,\n",
      "         -0.5476, -0.5698,  0.4259,  1.1555],\n",
      "        [ 2.0760, -1.0971,  0.6704, -0.8363,  0.0697, -0.9179,  0.5418,  0.0224,\n",
      "         -0.2133, -1.1332,  0.2417, -1.5240]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 变形\n",
    "x = torch.randn(2,3,4)\n",
    "print(x)\n",
    "print(x.view(2, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([5., 7., 9.])\n",
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 计算图， tensor 无法在计算中记录自己的父级关系，需要使用变量 ‘variable’ 类型\n",
    "# 从tensor中创建variable\n",
    "import torch.autograd as autograd\n",
    "x = autograd.Variable(torch.Tensor([1., 2., 3.]), requires_grad=True)\n",
    "print(x.data)\n",
    "# variable 支持tensor的所有运算\n",
    "y = autograd.Variable(torch.Tensor([4., 5., 6.]), requires_grad=True)\n",
    "z = x + y\n",
    "print(z.data)     \n",
    "# variable的特点就是，它在与你算中可以自动建立父子节点关系，知道是什么创建的\n",
    "# 发现creator属性名称已经改为grad_fn，很多文档还未进行修改\n",
    "s = z.sum()\n",
    "print(s)\n",
    "s.backward()\n",
    "print(x.grad)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4512, -0.0879, -0.3940,  1.2367,  1.2519],\n",
      "        [-0.3619,  1.0961,  0.7520, -0.2814, -0.3173]])\n",
      "tensor([[ 0.7133, -0.8994,  0.5450],\n",
      "        [ 0.2727, -0.0799,  0.3352]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 仿射映射\n",
    "import torch.nn as nn\n",
    "lin = nn.Linear(5, 3)\n",
    "# 2 行 5 列\n",
    "data = autograd.Variable(torch.randn(2, 5))\n",
    "print(data)\n",
    "print(lin(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3032,  0.5010],\n",
      "        [-1.6846,  1.4026]])\n",
      "tensor([[0.3032, 0.5010],\n",
      "        [0.0000, 1.4026]])\n",
      "tensor([[ 0.2943,  0.4629],\n",
      "        [-0.9335,  0.8859]])\n"
     ]
    }
   ],
   "source": [
    "# 非线性函数\n",
    "import torch.functional as F\n",
    "data = autograd.Variable(torch.randn(2, 2))\n",
    "print(data)\n",
    "#新版本中的这两个激活函数已经放到了torch里\n",
    "print(torch.relu(data))\n",
    "print(torch.tanh(data))\n",
    "# print(torch.sigmod(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3730, -0.5866, -0.5673, -1.3969, -0.2648])\n",
      "tensor([0.4045, 0.1549, 0.1579, 0.0689, 0.2138])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "data = autograd.Variable(torch.randn(5))\n",
    "print(data)\n",
    "print(torch.softmax(data, 0))\n",
    "print(torch.softmax(data, 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
